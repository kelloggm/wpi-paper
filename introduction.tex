\section{Introduction}
\label{sec:intro}

\todo{Explain the distinction between a ``specification'' and a type qualifier.}

\todo{Should we be more careful to distinguish type annotations (a
  Java syntactic construct) from type qualifiers (a type-theoretic
  concept)?}

A pluggable type system~\cite{FosterFFA99} augments a host type system
with \emph{type qualifiers} that refine it.  A qualified type is
finer-grained than an unqualified one and therefore gives more precise
information about what values are possible at run time.
Pluggable type systems are a standard practice in industry; for example,
they are used at Amazon~\cite{KelloggSTE2020,KelloggRSSE2020},
Google~\cite{SadowskiAEMCJ2018}, and Uber~\cite{BanerjeeCS2019}.
Pluggable type systems
can prevent\todo{Diversity citations for submission.  Ernst should not be the most-cited
  author in the citations in the submission (can be tied for first).
  Reinstate more citations (don't remove any) for camera-ready.}  null-pointer
dereferences~\cite{BanerjeeCS2019,PapiACPE2008,DietlDEMS2011},
array-bounds violations~\cite{KelloggDME2018},
violations of locking discipline~\cite{ErnstLMST2016},
mutations of immutable data~\cite{DietlDEMS2011,PapiACPE2008,coblenz2017glacier},
and more.
A successful type-checking run proves that the undesirable behavior will
never occur.

Pluggable types are an attractive verification and bug-finding strategy
because programmers
are familiar with type systems and are used to writing types.
% because
% they are programming in a host language like Java or C\# with static
% types.
The type qualifiers also serve as concise, machine-checked documentation.
However, writing type qualifiers in a legacy codebase
is time-consuming and intimidating for developers.
\todo{A sentence about \emph{type inference} as the solution.}

The traditional approach to type inference is constraint-based:
deducing types for a program from the program's structure
by solving a set of constraints induced by type uses.
\todo{Say something about how this is whole-program, somewhere.}
%
For example, languages like ML and Haskell
include Hindley-Milner type inference (based on algorithm
W~\cite{DamasM1982}), so programmers do not need to write types at all,
except as useful documentation\todo{Cite a ML or Haskell best practice}.
%
This approach is impractical\todo{Be specific.  Just inefficient?  If so,
  so what?  Ours is also inefficient.} for popular object-oriented programming
languages such as Java or Python, because subtyping prevents efficient
unification of types\todo{say something about row polymorphism as a
  possible alternative, as is done in OCaml, here?}.
%
Type inference for dynamically-typed languages like Python is an open
research problem. Researchers have proposed approaches based
on MaxSAT~\cite{hassan2018maxsmt} and machine learning~\cite{xu2016python,peng2022static}.

Unfortunately, none of these approaches is obviously practical for pluggable types.
%% Actually, this is basically what we're going to do, so I shouldn't be so harsh on it.
%% Building a type inference algorithm in the style of algorithm W for each
%% type system is impractical: there are too many pluggable type
%% systems.\todo{I don't buy this.  There aren't too many type systems to
%%   implement.  Doing a bit of extra work to define inference for each is a
%%   constant factor overhead over writing the type checker for each.}
A natural idea is to build a set of constraints based on the property the
pluggable type system is trying to prove (\eg, build constraints based on
nullability for a nullness pluggable type system, constraints based on indexing
for an array bounds system, \etc) and then dispatch those constraints
to a solver.
%
Unfortunately, this approach requires significant work for every pluggable type
system (as all of its type rules must be re-encoded as constraints) and rapidly
reduces to building an alternative verification tool, making it unattractive as
a general solution to the inference problem.
%
Approaches based on machine learning lack sufficient training data for
many pluggable type systems, they give no guarantee of correctness, and may
not be able to explain their choices to the programmer.
%
We desire an
inference algorithm that is \emph{generic} over the pluggable type system
to which it is applied in that same way that algorithm W is generic over
all Hindley-Milner type systems: the pluggable type system designer should not need to
modify their pluggable type system's implmentation in order to access
the benefits of type inference.

To that end, we propose a general type inference algorithm for pluggable type
systems that is applicable to any flow-sensitive pluggable type system.
Our key insight is that
practical frameworks for building pluggable type systems already provide
local type inference in the form of flow-sensitivity within the body
of methods.
We modify the framework to record inferred method, class, and field summaries
based on the results of flow-sensitive typechecking.
Our approach iteratively typechecks the program, using and improving the
summaries, until reaching a fixed point.
That fixed point is a candidate set of type qualifiers, which are
consistent with the program.

If the program typechecks with the candidate set of qualifiers, the program
is correct with respect to that type system.
If not, then the program contains a defect, or it is not internally
consistent, or its correctness is beyond the capabilities of the
typechecker (this is when a programmer would write a cast).
In any event, the inferred type qualifiers can help the programmer.
In our implementation, the user (a programmer) can decide whether to insert
the type qualifiers in the source code, or to store them in a side file.

We implemented this idea for the Checker Framework~\cite{PapiACPE2008},
a popular open-source pluggable type system
framework for Java.
%
\todo{There were some difficulties along the way---we're going to
impress you with our clever solution to tricky problems, and also how much
engineering we did.}
%
We used the extended Checker Framework to run \todo{X} different pluggable typecheckers
on \todo{some massive number of} lines of code to demonstrate that
our approach is both effective and general.
In experiments, our inference approach inferred \todo{Y\%} of human-written
type qualifiers.

\todo{Decide if we're actually going to do this.}
We also compared our approach to bespoke inference systems that build
systems of constraints for particular type systems, like nullness or
maybe CFI (if Werner is an author of this paper). We show that our approach
produces similarly-good results, but didn't require a ton of extra
implementation effort for each new type system.

Our contributions are:
\begin{itemize}
\item a novel type inference algorithm for flow-sensitive pluggable
  typecheckers (\cref{sec:core-algorithm});
\item a collection of enhancements to the algorithm that are necessary to
  make it practical (\cref{sec:difficulties});
\item an implementation of our new type inference algorithm within a framework
  for building pluggable typecheckers (\cref{sec:implementation});
\item an evaluation of our implementation, that shows that it can infer
  \todo{X}\% of human-written annotations in \todo{Y} projects totalling
  \todo{Z} lines of non-comment, non-blank Java code, across \todo{W} different
  pluggable typecheckers (\cref{sec:evaluation}); and,
\item a comparison of our generic algorithm to specialized inference
  techniques for specific typecheckers, which demonstrates that our generic
  approach is about as good at inferring annotations but requires less
  custom code (\cref{sec:comparison}).
\end{itemize}
